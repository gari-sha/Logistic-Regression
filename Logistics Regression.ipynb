{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the essential needed for logistic regression, plotting and confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n",
      "[0 0 0 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#creating our own data\n",
    "x = np.arange(10).reshape(-1,1)\n",
    "y = np.array([0,0,0,0,1,1,1,1,1,1])\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Creating an instance of class LogisticRegression\n",
    "#There are several optional parameter that define the behaviour of our model\n",
    "#penalty - it is a string ('l2' by default) that decided whether there is regularization and which approach to use. other options are 'l1','elasticnet' and 'none'\n",
    "#dual is a boolean (false by default) that decided whether to use primal(false) or dual formation(true)\n",
    "#tol is a floating-point no that defines the tolerance for stopping the procedure\n",
    "#c is a +ve floating-point number (1.0 by default) that defines the relative strength of regularization. smaller values indicate stronger regularization\n",
    "#fit_intercept is a boolean(true by default) that decides whether to calculate the intercept b0 (when true) or consider it equal to zero(when false)\n",
    "#intercept_scaling is a floating-point number (1.0 by default) that defines the scaling of the intercept b0\n",
    "#class_weigth is a dictionary, 'balanced', or None(default) that defines the weights related to each class. when None, all classes ave the weight one\n",
    "#random_state is an integer, an instance of numpy.RandomState, or None(default) that defines what pseudo-random number generator to use\n",
    "#solver is a string('liblinear' by default) that decides what solver to use for fitting the model.Other options are 'newton-cg', 'lbfgs', 'sag', and 'saga'.\n",
    "#max_iter is an integer (100 by default) that defines the maximum number of iterations by the solver during model fitting\n",
    "#multi_class is a string ('ovr' by default) that decided the approach to use for handling multiple classes. Other options are 'multinomial' and 'auto'\n",
    "#verbose is a non-negative integer (0 by default) that defines the verbosity for the 'liblinear' and 'lbfgs' solvers\n",
    "#warm_start is a Boolean (False by default) that decides whether to reuse the previously obtained solution\n",
    "#n_jobs is an integer or None by default that defines the number of parallel processes to use. None means to use one core while -1 to use all available cores\n",
    "#l1_ratio is either a floating-point number between zero and one or None(default). It defines the relative importance of the L1 part in the elastic-net regularization\n",
    "#'liblinear' solver doesn’t work without regularization.\n",
    "#'newton-cg', 'sag', 'saga', and 'lbfgs' don’t support L1 regularization.\n",
    "#'saga' is the only solver that supports elastic-net regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will fit the model to determine the coefficients\n",
    "\n",
    "model = LogisticRegression(solver='liblinear',random_state = 0).fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[-1.04608067]\n",
      "[[0.51491375]]\n"
     ]
    }
   ],
   "source": [
    "#the array of distinct values that y takes\n",
    "print(model.classes_)\n",
    "\n",
    "#the value of intercept b0\n",
    "print(model.intercept_)\n",
    "\n",
    "#the value of slope\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.74002157 0.25997843]\n",
      " [0.62975524 0.37024476]\n",
      " [0.5040632  0.4959368 ]\n",
      " [0.37785549 0.62214451]\n",
      " [0.26628093 0.73371907]\n",
      " [0.17821501 0.82178499]\n",
      " [0.11472079 0.88527921]\n",
      " [0.07186982 0.92813018]\n",
      " [0.04422513 0.95577487]\n",
      " [0.02690569 0.97309431]]\n",
      "[0 0 0 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#predict_prob returns the matrix of probabilities that the predicted output is zero or one (1-p(x), p(x))\n",
    "print(model.predict_proba(x))\n",
    "\n",
    "#we can get the acutal predictions by predict\n",
    "print(model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "#the accuracy of the model is \n",
    "print(model.score(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 1]\n",
      " [0 6]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix, it takes actual output and predicted output as its input\n",
    "#(true negative    false positive)\n",
    "#(false negative    true positive)\n",
    "print(confusion_matrix(y,model.predict(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visulization of the confusion matrix\n",
    "cm = confusion_matrix(y, model.predict(x))\n",
    "\n",
    "fig, ax =plt.subplots(figsize=(8,8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0,1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0,1), ticklabels=('Actuals 0s', 'Actuals 1s'))\n",
    "ax.set_ylim(1.5,-0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j,i, cm[i,j], ha='center', va='center', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.93      0.88      0.89        10\n",
      "weighted avg       0.91      0.90      0.90        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#to get more comprehensive report on classification \n",
    "print(classification_report(y,model.predict(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can also improve our model by setting the regularization strength c = 10.0\n",
    "model1 = LogisticRegression(solver='liblinear', C=10.0, random_state=0)\n",
    "model1.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.51335372]\n",
      "[[1.12066084]]\n",
      "[[0.97106534 0.02893466]\n",
      " [0.9162684  0.0837316 ]\n",
      " [0.7810904  0.2189096 ]\n",
      " [0.53777071 0.46222929]\n",
      " [0.27502212 0.72497788]\n",
      " [0.11007743 0.88992257]\n",
      " [0.03876835 0.96123165]\n",
      " [0.01298011 0.98701989]\n",
      " [0.0042697  0.9957303 ]\n",
      " [0.00139621 0.99860379]]\n",
      "[0 0 0 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(model1.intercept_)\n",
    "print(model1.coef_)\n",
    "print(model1.predict_proba(x))\n",
    "print(model1.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted probability\n",
      "[[0.81999686 0.18000314]\n",
      " [0.69272057 0.30727943]\n",
      " [0.52732579 0.47267421]\n",
      " [0.35570732 0.64429268]\n",
      " [0.21458576 0.78541424]\n",
      " [0.11910229 0.88089771]\n",
      " [0.06271329 0.93728671]\n",
      " [0.03205032 0.96794968]\n",
      " [0.0161218  0.9838782 ]\n",
      " [0.00804372 0.99195628]]\n",
      "\n",
      "predicted y\n",
      "[0 0 0 1 1 1 1 1 1 1]\n",
      "\n",
      "score_: 0.8\n",
      "\n",
      "confusion matrix:\n",
      "[[2 1]\n",
      " [1 6]]\n",
      "\n",
      "report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       0.86      0.86      0.86         7\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.76      0.76      0.76        10\n",
      "weighted avg       0.80      0.80      0.80        10\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lets change our y and see how well our model perform\n",
    "y1 = np.array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "model2 = LogisticRegression(solver = 'liblinear',C=10.0, random_state=0)\n",
    "model2.fit(x,y1)\n",
    "\n",
    "p_pred = model2.predict_proba(x)\n",
    "y_pred = model2.predict(x)\n",
    "score_ = model2.score(x,y1)\n",
    "conf_m = confusion_matrix(y1,y_pred)\n",
    "report = classification_report(y1,y_pred)\n",
    "\n",
    "print('predicted probability', p_pred ,sep='\\n', end='\\n\\n')\n",
    "print('predicted y', y_pred, sep='\\n', end='\\n\\n')\n",
    "print('score_:', score_, end='\\n\\n')\n",
    "print('confusion matrix:', conf_m, sep='\\n',end='\\n\\n')\n",
    "print('report:',report, sep='\\n',end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to keep in mind that logistic regression is essentially a linear classifier, so you theoretically can not make a logistic regression with an accuracy of 1 in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform the logitc regression using the statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sm.add_constant(x)\n",
    "y2 = np.array([0,1,0,0,1,1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 3.]\n",
      " [1. 4.]\n",
      " [1. 5.]\n",
      " [1. 6.]\n",
      " [1. 7.]\n",
      " [1. 8.]\n",
      " [1. 9.]]\n",
      "[0 1 0 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a model \n",
    "model_sm = sm.Logit(y2,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.350471\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "#fitting the model. We can eith use fit or if we want to apply li regularization, then using fit.regularized()\n",
    "result = model_sm.fit(method='newton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.972805    0.82240094]\n"
     ]
    }
   ],
   "source": [
    "print(result.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12208792 0.24041529 0.41872657 0.62114189 0.78864861 0.89465521\n",
      " 0.95080891 0.97777369 0.99011108 0.99563083]\n"
     ]
    }
   ],
   "source": [
    "#evaluating our model\n",
    "print(result.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print((result.predict(x) >= 0.5).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 1.]\n",
      " [1. 6.]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "print(result.pred_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   10\n",
      "Model:                          Logit   Df Residuals:                        8\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 07 May 2020   Pseudo R-squ.:                  0.4263\n",
      "Time:                        15:08:59   Log-Likelihood:                -3.5047\n",
      "converged:                       True   LL-Null:                       -6.1086\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.02248\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.9728      1.737     -1.136      0.256      -5.377       1.431\n",
      "x1             0.8224      0.528      1.557      0.119      -0.213       1.858\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Results: Logit\n",
      "===============================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.426   \n",
      "Dependent Variable: y                AIC:              11.0094 \n",
      "Date:               2020-05-07 15:09 BIC:              11.6146 \n",
      "No. Observations:   10               Log-Likelihood:   -3.5047 \n",
      "Df Model:           1                LL-Null:          -6.1086 \n",
      "Df Residuals:       8                LLR p-value:      0.022485\n",
      "Converged:          1.0000           Scale:            1.0000  \n",
      "No. Iterations:     7.0000                                     \n",
      "-----------------------------------------------------------------\n",
      "          Coef.    Std.Err.      z      P>|z|     [0.025   0.975]\n",
      "-----------------------------------------------------------------\n",
      "const    -1.9728     1.7366   -1.1360   0.2560   -5.3765   1.4309\n",
      "x1        0.8224     0.5281    1.5572   0.1194   -0.2127   1.8575\n",
      "===============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.summary2())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
